---
title: "TFM - UNED Kaggle House Prices: Advanced Regression Techniques with caret"
subtitle: "Support Vector Machines with Radial Basis Function Kernel"
author: "Juan Carlos Santiago Culebras"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  #html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F, warning=F)
```

Proceso de evaluación del “Master de BigData – UNED“. 

Este documento es un resumen del TFM realizado para el "Máster Big Data y Business Analytics UNED 2018/2019" sobre la competición de Kaggle "House Prices: Advanced Regression Techniques"

Gran parte de este proyecto se ha realizado sobre la guía de RPubs “Machine Learning con R y caret” de Joaquín Amat Rodrigo, al cual doy las gracias por esta y todas sus contribuciones en RPubs.

# Primeros pasos 

## Librerías

Realizamos la carga de las librerías necesarias

```{r, warning=FALSE, results='hide'}

if(!is.element("dplyr", installed.packages()[, 1]))
      install.packages("dplyr", repos = 'http://cran.us.r-project.org')
library(dplyr)

if(!is.element("tidyr", installed.packages()[, 1]))
      install.packages("tidyr", repos = 'http://cran.us.r-project.org')
library(tidyr)

if(!is.element("ggplot2", installed.packages()[, 1]))
      install.packages("ggplot2", repos = 'http://cran.us.r-project.org')
library(ggplot2)

if(!is.element("grid", installed.packages()[, 1]))
      install.packages("grid", repos = 'http://cran.us.r-project.org')
library(grid)

if(!is.element("gridExtra", installed.packages()[, 1]))
      install.packages("gridExtra", repos = 'http://cran.us.r-project.org')
library(gridExtra)

if(!is.element("ggpubr", installed.packages()[, 1]))
      install.packages("ggpubr", repos = 'http://cran.us.r-project.org')
library(ggpubr)

if(!is.element("tibble", installed.packages()[, 1]))
      install.packages("tibble", repos = 'http://cran.us.r-project.org')
library(tibble)

if(!is.element("caret", installed.packages()[, 1]))
      install.packages("caret", repos = 'http://cran.us.r-project.org')
library(caret)

if(!is.element("recipes", installed.packages()[, 1]))
      install.packages("recipes", repos = 'http://cran.us.r-project.org')
library(recipes)

```

## Cargamos datos

```{r, results='hide'}
dsTrain <- read.csv("./input/train.csv")
dsTest <- read.csv("./input/test.csv")
```

## Conjunto Unificado

Juntamos los datos de entrenamiento con los de test para realizar el estudio y las transformaciones pertinentes sobre todos los datos.

 * Añadimos SalePrice al conjunto de Test con valor NA 
 * Marcamos datos de entrenamiento y test

```{r, results='hide'}

dsTest <- dsTest %>% 
  mutate(SalePrice = as.integer(NA), indTrain = 0)

dsDataAll <- dsTrain %>%
  mutate(indTrain = 1) %>%
  union(dsTest) %>%
  select(SalePrice, indTrain, everything())

dsDataAll$indTrain <- as.factor(dsDataAll$indTrain)

# Elimino los conjuntos originales
rm(dsTrain)
rm(dsTest)

```


# Fase 01 

Antes de implemetar esta fase se ha realizado un estudio completo del dataset, que no incluyo por la extensión que implica. En ella se han realizado las siguientes acciones:
* Análisis descriptivo
* Verificación de contenido de campos nominales
* Búsqueda de valores faltantes
* Verificaciones de los tipos de datos
* Búsqueda y eliminación de valores atípicos
* Estudio de correlaciones

Seguidamente se muestra la limpieza que se ha generado.

## Limpieza y preparación de los datos

Convertimos variables factor a texto, para posteriormente corregir valores
```{r, results='hide'}
dsDataAll <- dsDataAll %>%
  mutate_if(is.factor, as.character)

# Dejamos el indicador de entrenamiento como factor
dsDataAll$indTrain <- as.factor(dsDataAll$indTrain)
```


### Verificación y corrección de contenido de datos campos Nominales y Ordinales

Corrección de errores
```{r}

# Normalizar valores para los campos Exterior1st / Exterior2nd -> cambio valor en excel a 
#  Wd Sdng: Wood Siding
#  Wd Shng:	Wood Shingles
dsDataAll <- dsDataAll %>% mutate(Exterior1st = ifelse(Exterior1st=="WdShing","WdShng",Exterior1st))
dsDataAll <- dsDataAll %>% mutate(Exterior1st = ifelse(Exterior1st=="Wd Sdng","WdSdng",Exterior1st))
dsDataAll <- dsDataAll %>% mutate(Exterior1st = ifelse(Exterior1st=="Wd Shng","WdShng",Exterior1st))

# Exterior2nd CmentBd el valor real es CemntBd (al igual que Exterior1st) filter(dsDataAll,Exterior1st=="CemntBd")
dsDataAll <- dsDataAll %>% mutate(Exterior2nd = ifelse(Exterior2nd=="CmentBd","CemntBd",Exterior2nd))
dsDataAll <- dsDataAll %>% mutate(Exterior2nd = ifelse(Exterior2nd=="Wd Sdng","WdSdng",Exterior2nd))
dsDataAll <- dsDataAll %>% mutate(Exterior2nd = ifelse(Exterior2nd=="Wd Shng","WdShng",Exterior2nd))
dsDataAll <- dsDataAll %>% mutate(Exterior2nd = ifelse(Exterior2nd=="Brk Cmn","BrkComm",Exterior2nd))

dsDataAll <- dsDataAll %>% mutate(MSZoning = ifelse(MSZoning=="C (all)","C",MSZoning))
dsDataAll <- dsDataAll %>% mutate(RoofMatl = ifelse(RoofMatl=="Tar&Grv","Tar",RoofMatl))

```

### Valores faltantes - Missing Data

La gran mayoría de algoritmos no aceptan observaciones incompletas, por lo que, cuando el set de datos contiene valores ausentes, se puede:

* Eliminar aquellas observaciones que estén incompletas.
* Eliminar aquellas variables que contengan valores ausentes.
* Tratar de estimar los valores ausentes empleando el resto de información disponible (imputación).

Identifico valores faltantes

```{r}

missingData <- dsDataAll %>%
  summarise_all(funs(sum(is.na(.)))) %>% 
  gather("column") %>%
  rename(NumNAs = value) %>% 
  mutate(PrcNAs = NumNAs/nrow(dsDataAll)) %>% 
  filter(NumNAs!=0) %>%
  arrange(desc(PrcNAs))

head(missingData) # presento solo los primeros 

```

Las variables con un porcentaje de valores asuntes muy alto (>80%) las excluimos del modelo, ya que pueden dar errores al realizar subconjuntos de datos pare entrenar y validar los modelos.

```{r}

# PoolQC - Calidad de la piscina
# MiscFeature -  características varias no cubiertas en otras categorías
# Alley - tipo de acceso al callejón
# Fence - calidad de la cerca

eliminar <- filter(missingData, PrcNAs > 0.80) %>% select(column)

dsDataAll <- dsDataAll %>% 
    select(-c(eliminar$column))

rm(eliminar)

```

Del resto de valores pendientes realizo estudio y modifico valores faltantes.

```{r}

dsDataAll <- select(dsDataAll, -Utilities)

#Ordinales asigno texto None
dsDataAll <- mutate(dsDataAll, FireplaceQu = ifelse(is.na(FireplaceQu),"None",FireplaceQu))
dsDataAll <- mutate(dsDataAll, GarageCond = ifelse(is.na(GarageCond),"None",GarageCond))
dsDataAll <- mutate(dsDataAll, GarageQual = ifelse(is.na(GarageQual),"None",GarageQual))
dsDataAll <- mutate(dsDataAll, GarageFinish = ifelse(is.na(GarageFinish),"None",GarageFinish))
dsDataAll <- mutate(dsDataAll, GarageType = ifelse(is.na(GarageType),"None",GarageType))
dsDataAll <- mutate(dsDataAll, BsmtFinType2 = ifelse(is.na(BsmtFinType2),"None",BsmtFinType2))
dsDataAll <- mutate(dsDataAll, BsmtQual = ifelse(is.na(BsmtQual),"None",BsmtQual))
dsDataAll <- mutate(dsDataAll, BsmtCond = ifelse(is.na(BsmtCond),"None",BsmtCond))
dsDataAll <- mutate(dsDataAll, BsmtExposure = ifelse(is.na(BsmtExposure),"None",BsmtExposure))
dsDataAll <- mutate(dsDataAll, BsmtFinType1 = ifelse(is.na(BsmtFinType1),"None",BsmtFinType1))
dsDataAll <- mutate(dsDataAll, MasVnrType = ifelse(is.na(MasVnrType),"None",MasVnrType))

#Discretas y continuas 0 
dsDataAll <- mutate(dsDataAll, GarageYrBlt = ifelse(is.na(GarageYrBlt),0,GarageYrBlt))
dsDataAll <- mutate(dsDataAll, GarageCars = ifelse(is.na(GarageCars),0,GarageCars))
dsDataAll <- mutate(dsDataAll, GarageArea = ifelse(is.na(GarageArea),0,GarageArea))
dsDataAll <- mutate(dsDataAll, TotalBsmtSF = ifelse(is.na(TotalBsmtSF),0,TotalBsmtSF))
dsDataAll <- mutate(dsDataAll, BsmtFinSF1 = ifelse(is.na(BsmtFinSF1),0,BsmtFinSF1))
dsDataAll <- mutate(dsDataAll, BsmtFinSF2 = ifelse(is.na(BsmtFinSF2),0,BsmtFinSF2))
dsDataAll <- mutate(dsDataAll, BsmtUnfSF = ifelse(is.na(BsmtUnfSF),0,BsmtUnfSF))
dsDataAll <- mutate(dsDataAll, BsmtFullBath = ifelse(is.na(BsmtFullBath),0,BsmtFullBath))
dsDataAll <- mutate(dsDataAll, BsmtHalfBath = ifelse(is.na(BsmtHalfBath),0,BsmtHalfBath))
dsDataAll <- mutate(dsDataAll, MasVnrArea = ifelse(is.na(MasVnrArea),0,MasVnrArea))

dsDataAll <- mutate(dsDataAll, LotFrontage = ifelse(is.na(LotFrontage),mean(dsDataAll$LotFrontage,na.rm = TRUE),LotFrontage))

# Nominales asigno valor medio
dsDataAll <- mutate(dsDataAll, MSZoning = ifelse(is.na(MSZoning),"RL",MSZoning))
dsDataAll <- mutate(dsDataAll, Functional = ifelse(is.na(Functional),"Typ",Functional))
dsDataAll <- mutate(dsDataAll, Exterior1st = ifelse(is.na(Exterior1st),"VinylSd",Exterior1st))
dsDataAll <- mutate(dsDataAll, Exterior2nd = ifelse(is.na(Exterior2nd),"VinylSd",Exterior2nd))
dsDataAll <- mutate(dsDataAll, Electrical = ifelse(is.na(Electrical),"SBrkr",Electrical))
dsDataAll <- mutate(dsDataAll, KitchenQual = ifelse(is.na(KitchenQual),"TA",KitchenQual))
dsDataAll <- mutate(dsDataAll, SaleType = ifelse(is.na(SaleType),"WD",SaleType))

missingData <- dsDataAll %>%
  summarise_all(funs(sum(is.na(.)))) %>% 
  gather("column") %>%
  rename(NumNAs = value) %>% 
  mutate(PrcNAs = NumNAs/nrow(dsDataAll)) %>% 
  filter(NumNAs!=0) %>%
  arrange(desc(PrcNAs))

rm(missingData)
```

### Conversión de variables ordinales a numéricas

```{r}
dsDataAll$ExterQual <- factor(dsDataAll$ExterQual, levels = rev(c("Ex","Gd","TA","Fa","Po")))
dsDataAll$ExterQual <- as.numeric(c(dsDataAll$ExterQual))

dsDataAll$ExterCond <- factor(dsDataAll$ExterCond, levels = rev(c("Ex","Gd","TA","Fa","Po")))
dsDataAll$ExterCond <- as.numeric(c(dsDataAll$ExterCond))

dsDataAll$LotShape <- factor(dsDataAll$LotShape, levels = rev(c("Reg","IR1","IR2","IR3")))
dsDataAll$LotShape <- as.numeric(c(dsDataAll$LotShape))

dsDataAll$LandSlope <- factor(dsDataAll$LandSlope, levels = rev(c("Gtl","Mod","Sev")))
dsDataAll$LandSlope <- as.numeric(c(dsDataAll$LandSlope))

dsDataAll$BsmtQual <- factor(dsDataAll$BsmtQual, levels = rev(c("Ex","Gd","TA","Fa","Po","None")))
dsDataAll$BsmtQual <- as.numeric(c(dsDataAll$BsmtQual))-1

dsDataAll$BsmtCond <- factor(dsDataAll$BsmtCond, levels = rev(c("Ex","Gd","TA","Fa","Po","None")))
dsDataAll$BsmtCond <- as.numeric(c(dsDataAll$BsmtCond))-1

dsDataAll$BsmtExposure <- factor(dsDataAll$BsmtExposure, levels = rev(c("Gd","Av","Mn","No","None")))
dsDataAll$BsmtExposure <- as.numeric(c(dsDataAll$BsmtExposure))-1

dsDataAll$BsmtFinType1 <- factor(dsDataAll$BsmtFinType1, levels = rev(c("GLQ","ALQ","BLQ","Rec","LwQ","Unf","None")))
dsDataAll$BsmtFinType1 <- as.numeric(c(dsDataAll$BsmtFinType1))-1

dsDataAll$BsmtFinType2 <- factor(dsDataAll$BsmtFinType2, levels = rev(c("GLQ","ALQ","BLQ","Rec","LwQ","Unf","None")))
dsDataAll$BsmtFinType2 <- as.numeric(c(dsDataAll$BsmtFinType2))-1

dsDataAll$HeatingQC <- factor(dsDataAll$HeatingQC, levels = rev(c("Ex","Gd","TA","Fa","Po")))
dsDataAll$HeatingQC <- as.numeric(c(dsDataAll$HeatingQC))

dsDataAll$Electrical <- factor(dsDataAll$Electrical, levels = rev(c("SBrkr","FuseA","FuseF","FuseP","Mix")))
dsDataAll$Electrical <- as.numeric(c(dsDataAll$Electrical))

dsDataAll$KitchenQual <- factor(dsDataAll$KitchenQual, levels = rev(c("Ex","Gd","TA","Fa","Po")))
dsDataAll$KitchenQual <- as.numeric(c(dsDataAll$KitchenQual))

dsDataAll$Functional <- factor(dsDataAll$Functional, levels = rev(c("Typ","Min1","Min2","Mod","Maj1","Maj2","Sev","Sal")))
dsDataAll$Functional <- as.numeric(c(dsDataAll$Functional))

dsDataAll$FireplaceQu <- factor(dsDataAll$FireplaceQu, levels = rev(c("Ex","Gd","TA","Fa","Po","None")))
dsDataAll$FireplaceQu <- as.numeric(c(dsDataAll$FireplaceQu))-1

dsDataAll$GarageFinish <- factor(dsDataAll$GarageFinish, levels = rev(c("Fin","RFn","Unf","None")))
dsDataAll$GarageFinish <- as.numeric(c(dsDataAll$GarageFinish))-1

dsDataAll$GarageQual <- factor(dsDataAll$GarageQual, levels = rev(c("Ex","Gd","TA","Fa","Po","None")))
dsDataAll$GarageQual <- as.numeric(c(dsDataAll$GarageQual))-1

dsDataAll$GarageCond <- factor(dsDataAll$GarageCond, levels = rev(c("Ex","Gd","TA","Fa","Po","None")))
dsDataAll$GarageCond <- as.numeric(c(dsDataAll$GarageCond))-1

dsDataAll$PavedDrive <- factor(dsDataAll$PavedDrive, levels = rev(c("Y","P","N")))
dsDataAll$PavedDrive <- as.numeric(c(dsDataAll$PavedDrive))

```

### Variables Nominales paso a factor

Todas las variables que quedan con caracter son nominales 
```{r}
dsDataAll <- dsDataAll %>% 
    mutate_if(is.character, as.factor)

dsDataAll$MSSubClass <- as.factor(dsDataAll$MSSubClass)
```

Variables con solo dos valores se pasan a númericas

$ Street       : Factor w/ 2 levels "Grvl","Pave"
$ CentralAir   : Factor w/ 2 levels "N","Y"
 
```{r}

#  Grvl:  12 
#  Pave:2907

dsDataAll$StreetPave[dsDataAll$Street != "Pave"] <- "0"
dsDataAll$StreetPave[dsDataAll$Street == "Pave"] <- "1"
dsDataAll$StreetPave <- as.numeric(dsDataAll$StreetPave)
dsDataAll <- select(dsDataAll, -Street)

# CentralAir
# Y:2723
# N: 196

dsDataAll$CentralAir <- as.character(dsDataAll$CentralAir)
dsDataAll$CentralAir[dsDataAll$CentralAir != "Y"] <- "0"
dsDataAll$CentralAir[dsDataAll$CentralAir == "Y"] <- "1"
dsDataAll$CentralAir <- as.numeric(dsDataAll$CentralAir)

```

### Valores atípicos - outliers

**GrLivArea** superficie habitable por encima del nivel del suelo (pies cuadrados)
Existen 2 valores atípicos son muy altos para el precio que tienen en el conjunto de entrenamiento, estas filas se eliminarán al ser esta una variable principal para el proceso de predicción


```{r}
# Se eliminan las filas 
eliminar <- dsDataAll %>% 
    filter(indTrain==1&GrLivArea>4500) %>% 
    select(Id, GrLivArea, SalePrice, indTrain)

dsDataAll <- dsDataAll %>%
  anti_join(eliminar,by="Id")

rm(eliminar)
```

**LotArea**	 tamaño del lote en pies cuadrados
Existen 4 valores claramente fuera de rango, creo variable nueva actualizandolos con los valores con la mediana según el tipo de construcción

```{r}
# Calculo mediana por tipo de construcción
lotAreaMedian <- select(dsDataAll,BldgType,LotArea) %>%
    group_by(BldgType) %>% 
    summarise(medianLotArea = median(LotArea))

f <- function(x){
  a <- as.numeric(lotAreaMedian[lotAreaMedian$BldgType==x,2])
  return(a)
}

# Seleccion Outliers
outlier_values <- as.data.frame(boxplot.stats(dsDataAll$LotArea)$out) 
names(outlier_values) = "LotArea"
outlier_values$LotArea <- as.numeric(outlier_values$LotArea)
outlier_values <- outlier_values %>% 
  arrange(desc(LotArea)) %>%    
  top_n(4)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(LotArea = ifelse(LotArea>=115149,f(BldgType),LotArea))	

rm(outlier_values)
rm(lotAreaMedian)
rm(f)
```

**LowQualFinSF** pies cuadrados terminados de baja calidad (todos los pisos)
Parece que existe un par de valores extraños, creo variable nueva y actualizo a la mediana de todos los valores no cero

```{r}
a <- dsDataAll %>% 
    select(LowQualFinSF) %>% 
    filter(LowQualFinSF!=0) 

# Parece que existe un par de valores extraños 
# Actualizo a la mediana de todos los valores no cero
medianLowQualFinSF <- median(a$LowQualFinSF)

#select(data,Id,LowQualFinSF) %>% filter(LowQualFinSF>600)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(LowQualFinSF = ifelse(LowQualFinSF>600,medianLowQualFinSF,LowQualFinSF))	

rm(medianLowQualFinSF)
rm(a)
```

**MasVnrArea** área de revestimiento de mampostería en pies cuadrados
Identifico un valor extraño
```{r}
a <- dsDataAll %>% 
    select(MasVnrArea) %>% 
    filter(MasVnrArea!=0) 

# Parece que existe un valor extraño 
# Actualizo a la mediana de todos los valores no cero
medianMasVnrArea <- median(a$MasVnrArea)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(MasVnrArea = ifelse(MasVnrArea>1500,medianMasVnrArea,MasVnrArea))	


rm(medianMasVnrArea)
rm(a)

```

**WoodDeckSF** área de cubierta de madera en pies cuadrados
Parece que existe un valor extraño, sin embargo existe la posibilidad de que sea una casa completamente de madera,
pero como el valor esta en el conjunto de test no se puede usar para entrenar y el modelo resultante no podrá calcular precios para casas solo de madera, por lo que actualizo el valor a la mediana según la superficie

```{r}
a <- dsDataAll %>% 
    filter(WoodDeckSF!=0 & GrLivArea > 1300 & GrLivArea < 1400) %>% 
    select(WoodDeckSF)
    
medianWoodDeckSF <- median(a$WoodDeckSF)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(WoodDeckSF = ifelse(WoodDeckSF>1500,medianWoodDeckSF,WoodDeckSF))	

rm(medianWoodDeckSF)
rm(a)

```


**OpenPorchSF** área de porche abierto en pies cuadrados
Identifico un par de valores extraños Uno en el conjunto de entrenamiento, con un porche muy grande y un precio bajo y Otro en el conjunto de test, con una superficie muy grande

```{r}

a <- dsDataAll %>% 
    filter(OpenPorchSF!=0 & GrLivArea > 700 & GrLivArea < 750) %>% 
    select(OpenPorchSF)
    
medianOpenPorchSF <- median(a$OpenPorchSF)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(OpenPorchSF = ifelse(OpenPorchSF>500&GrLivArea<1000,medianOpenPorchSF,OpenPorchSF))	


a <- dsDataAll %>% 
    filter(OpenPorchSF!=0 & GrLivArea > 2550 & GrLivArea < 2650) %>% 
    select(OpenPorchSF)
    
medianOpenPorchSF <- median(a$OpenPorchSF)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(OpenPorchSF = ifelse(OpenPorchSF>600,medianOpenPorchSF,OpenPorchSF))

rm(medianOpenPorchSF)
rm(a)

```

**EnclosedPorch** área de porche cerrado en pies cuadrados
Parece que existen un valor extraño en el conjunto de test, con una superficie muy grande

```{r}

## Asigno mediana segun el area  
a <- dsDataAll %>% 
    filter(EnclosedPorch!=0 & GrLivArea > 1800 & GrLivArea < 1850) %>% 
    select(EnclosedPorch)
    
medianEnclosedPorch <- median(a$EnclosedPorch)

# Modificación directa
dsDataAll <- dsDataAll %>%
  rowwise() %>%
	mutate(EnclosedPorch = ifelse(OpenPorchSF>600,medianEnclosedPorch,EnclosedPorch))	

rm(medianEnclosedPorch)
rm(a)

```

**YearRemodAdd** Año de remodelación
Parece que a las casas que se construyeron antes de 1950 se les puso una fecha de remodelación 1950
Modifico la fecha de remodelación para casas anteriores a 1950 asignandoles la fecha de construcción

```{r}
dsDataAll <- dsDataAll %>% 
  mutate(YearRemodAdd = ifelse(YearBuilt<1950 & YearRemodAdd==1950,YearBuilt,YearRemodAdd)) 
```

**GarageYrBlt** año en que se construyó el garaje
Los datos de esta variable parecen incorrectos (Elimino)
```{r}
dsDataAll <- select(dsDataAll, -GarageYrBlt)
```

*Salvar progreso*
```{r}
save(dsDataAll, file = './F01_Datos/F01_dsDataAll.RData')
#load('./F01_Datos/F01_dsDataAll.RData')
```



# Fase 02 Ingeniería de características con recipe

En esta fase se intentará modificar el conjunto de características para aumentar su eficacia predictiva, para lo cual se utilizará el paquete “recipes”.


Preparamos datos para realizar la ingenieria con recipe

La variable objetivo SalePrice no se modificará con caret, se normalizará directamente con la función log ya que la competición se basa en la medida RMSE del logaritmo de SalePrice.

```{r}
dsDataAllRecipe <- dsDataAll %>%
  mutate(SalePrice = log(SalePrice)) 
```

## Separamos los datos 

Optenemos 3 dataset (dsTest no se utilizara en esta fase)

dsTrain - Que a su vez se divide en
  dsTrain.training
  dsTrain.CV 
  
```{r}

dsTrain <- dsDataAllRecipe %>%
  filter(indTrain == 1) %>%
  select(SalePrice, everything()) %>%
  select(-c(Id,indTrain))

dim(dsTrain)

set.seed(123)
iTrain  <- createDataPartition(y=dsTrain$SalePrice, p=0.7, list=F)

dsTrain.training <- dsTrain[iTrain, ]
dsTrain.CV       <- dsTrain[-iTrain, ]

```

## Objeto inicial

Se crea un objeto recipe() con la variable respuesta y los predictores

```{r}
objRecipe <- recipe(formula = SalePrice ~ ., data =  dsTrain.training)

```

## Generamos los pasos 

*Eliminación variables con varianza próxima a cero: Si una variable tiene casi todas las observaciones con un mismo valor, su varianza será próxima a cero. Estas variables pueden añadir más ruido que información, también dan problemas cuando se seleccionan los conjuntos de entrenamiento ya que si en la variable solo queda un valor puede producir que el entrenamiento sea erróneo.

*Estandarización y escalado, sobre las variables numéricas: En el análisis inicial se detectó que la mayoría de las variables continuas están sesgadas.

*Binarización de variables nominales (dummy):Todas las variables nominales se convertirán a numéricas binarias, para ello cada variable generara nuevas variables una por cada valor existente en el conjunto de datos, indicando como valor 0 o 1, ausencia o presencia del valor.

*Se repite la eliminación de variables con varianza cero, ya que muchas de las variables dummy tendrán este problema. Una varianza cero puede generar problemas con algunos modelos.

```{r}
# Eliminación variables con varianza próxima a cero
objRecipe <- objRecipe %>% step_nzv(all_predictors())

# Estandarización y escalado, sobre las variables numéricas
objRecipe <- objRecipe %>% step_center(all_numeric(), -SalePrice)
objRecipe <- objRecipe %>% step_scale(all_numeric(), -SalePrice)

#Binarización de variables nominales
objRecipe <- objRecipe %>% step_dummy(all_nominal(), -all_outcomes())

# Eliminación variables con varianza próxima a cero para DUMMY
objRecipe <- objRecipe %>% step_nzv(all_predictors())
```

Comprobamos el objeto Recipe
```{r}
objRecipe
```


## Entrenamiento

Se realiza un entrenamiento del objeto recipe, donde se aprenden los parámetros necesarios para realizar las transformaciones y se muestra el reusltado del entrenamiento

```{r}
trained_recipe <- prep(objRecipe, training = dsTrain.training)
trained_recipe
```


Se aplican las transformaciones a los conjuntos deseados, en nuestro caso se realizará sobre todos los datos conjunto de entrenamiento y de test, ya que será la entrada de la siguiente fase.
```{r}

dsDataAllRecipe.prep <- bake(trained_recipe, new_data = dsDataAllRecipe)

#Guardamos en el dataset dsDataAll los resultados incluidos los campos Id e indTrain
dsDataAll <- cbind(dsDataAllRecipe[,1:3], dsDataAllRecipe.prep[,-1])

```


# Fase 03 Selección de predictores con caret

El objetivo es utilizar una de las muchas formas de reducir el volumen de características que ofrece caret, de tal forma que únicamente los predictores que están relacionados con la variable respuestas se incluyan en el modelo.

Los métodos de selección de predictores se pueden clasificar como:
*	Métodos wrapper: evalúan múltiples modelos utilizando procedimientos que agregan y/o eliminan predictores para encontrar la combinación óptima que maximice el rendimiento del modelo, son algoritmos de búsqueda donde los predictores son las entradas y el modelo a optimizar es la salida.
** Eliminación de características recursivas
** Algoritmos genéticos
** Simulated annealing
*	Métodos de filtro: Analizan la relación que tiene cada predictor con la variable respuesta, evaluando la relevancia de los predictores fuera de los modelos y seleccionando los que pasan algún criterio.

Además, cada uno de estos métodos puede utilizar distintos algoritmos (regresión lineal, naive bayes, random forest) y métodos de entrenamiento (Validación cruzada o bootstrapping).

El método seleccionado para realizar la selección de predictores es Eliminación Recursiva con Randon Forest y el método de evaluación, la validación cruzada con 5 particiones y 5 repeticiones, 


## Separamos de nuevo los datos 

Separamos los datos modificados con recipe

Obtenemos 4 dataset

dsTrain - Que a su vez se divide en
  dsTrain.training
  dsTrain.CV 
  
dsTest

```{r}

dsTrain <- dsDataAll %>%
  filter(indTrain == 1) %>%
  select(SalePrice, everything()) %>%
  select(-c(Id,indTrain))

dim(dsTrain)

set.seed(123)
iTrain  <- createDataPartition(y=dsTrain$SalePrice, p=0.7, list=F)

dsTrain.training <- dsTrain[iTrain, ]
dsTrain.CV       <- dsTrain[-iTrain, ]

dsTest <- dsDataAll %>%
  filter(indTrain == 0) %>%
  select(SalePrice, everything()) 

```


## Eliminación Recursiva con Randon Forest y validación cruzada

EJECUCIÓN
```{r}

#Defino conjuntos de número de predictores a probar.
subsets <- c(5, 10, 12, 14, 16, 18, 20, 25, 30, 35, 40, 50, 60)

control <- rfeControl(functions = rfFuncs
                      ,method = "repeatedcv" # Validación cruzada
                      ,repeats = 5
                      ,verbose = FALSE)

t <- proc.time() # Inicia el cronómetro
rf_rfe <- rfe(SalePrice ~ .
              , data = dsTrain.training         
              , sizes = subsets
              , metric = "RMSE"
              , rfeControl = control)
proc.time()-t    # Detiene el cronómetro

#load('./F03_SelPredictores/F02_03_dsDataAll_Recipe/F03_2_rfe_rf.RData')

#    user  system elapsed 
# 3044.24   16.42 3072.58 

rf_rfe

```

Estudio de resultados 

Presentamos graficamente la evolución de RMSE según el número de predictores seleccionados.

Se marcan los números de predictores con mejor RMSE Absoluto y los que mejor Rendimiento ofrecen según la función pickSizeTolerance.


```{r}
dsResults <- rf_rfe$results

# Métricas promedio de cada tamaño
dsResults %>% 
  group_by(Variables) %>%
  summarise(media_RMSE = mean(RMSE), media_Rsquared = mean(Rsquared)) %>%
  arrange(media_RMSE)


mejorAbsoluto <- pickSizeBest(select(dsResults,RMSE,Variables)
                              , metric = "RMSE"
                              , maximize = FALSE)
mejorRendimiento <- pickSizeTolerance(select(dsResults,RMSE,Variables)
                                  , metric = "RMSE"
                                  , maximize = FALSE)

## Percent Loss in performance (positive)
# ToDo: example$PctLoss <- (example$RMSE - min(example$RMSE))/min(example$RMSE)*100

# Gráfica de disminución de RMSE
ggplot(data = dsResults, aes(x = Variables, y = RMSE)) +
  geom_line(color = "blue") +
  scale_x_continuous(breaks = unique(dsResults$Variables)) +
  geom_point() +
  geom_errorbar(aes(ymin = RMSE - RMSESD, ymax = RMSE + RMSESD),
                width = 0.2) +
  
  geom_point(data = filter(dsResults, Variables==mejorAbsoluto) 
             , shape=0, cex= 1.5, color = "red") +
  
  geom_point(data = filter(dsResults, Variables==mejorRendimiento)
             , shape = 4, cex= 1.5, color = "green") +

  theme_bw()


```

Selección las variables indicadas como mejor rendimiento (18 Variables)
```{r}

dsVarSel001 <- as.data.frame(rf_rfe$optVariables) %>%
  rename(Campo = 1) %>%
  rownames_to_column("Orden") %>%
  mutate(Orden = as.numeric(Orden), Campo = as.character(Campo)) 

# Selecciono los 25 primeros selectores.
dsVarSel <- dsVarSel001 %>% top_n(-18, Orden)

# Guardo un data set con los valores seleccionados
dsDataAllVarSel <- dsDataAll %>% 
    select(SalePrice, indTrain, Id, c(dsVarSel$Campo))

```

Eliminamos objetos que no se seguiran usando
```{r}
rm(list= ls()[!(ls() == 'dsDataAllVarSel')])
```


# Fase 04 Selección de modelos predictivos con caret

En esta fase aplicaremos distintos algoritmos de machine learning para generar modelos de regresión, que sean capaces de predecir la variable objetivo (SalePrice). 


Creamos una función de apoyo para presentar los resultados obtenidos al entrenar un modelo.

Presenta: 
* Modelo final: Resumen del modelo seleccionado en el entrenamiento y cuáles son los mejores parámetros.

* Estudio del RMSE obtenido en la validación
Para ello se presentan dos gráficas:
** Gráfica de densidad de RMSE de los distintos cálculos realizados en el entrenamiento.
** Boxplot de RMSE de los distintos cálculos
El resumen del RMSE obtenido para el entrenamiento
*	Summary de resample$RMSE
Y por último el error de test
*	Para ello la función llama a predict sobre el modelo con el conjunto dsTrain.CV ver Gestión de los dataset - Pruebas de Test)


```{r}

fnEstudioModelo <- function ( modelo , estudioParam = TRUE){
  
  # modelo
  # modelo$finalModel
  
  
  p1 <- ggplot(data = modelo$resample, aes(x = RMSE)) +
        geom_density(alpha = 0.5, fill = "gray50") +
        geom_vline(xintercept = mean(modelo$resample$RMSE),
                   linetype = "dashed") +
        theme_bw()

  p2 <- ggplot(data = modelo$resample, aes(x = 1, y = RMSE)) +
        geom_boxplot(outlier.shape = NA, alpha = 0.5, fill = "gray50") +
        geom_jitter(width = 0.05) +
        labs(x = "") +
        theme_bw() +
        theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

  #trellis.par.set(caretTheme())
  if (estudioParam){
    p3 <- plot(modelo)  
  }
  
  # Error de test
  predicciones <- predict(modelo
                          , newdata = dsTrain.CV
                          , type = "raw")

  # RMSE(predicciones, dsTrain.CV$SalePrice)
  # MAE(predicciones, dsTrain.CV$SalePrice)
  # R2(predicciones, dsTrain.CV$SalePrice, form = "traditional")
  
  
  t1 <- capture.output(summary(modelo$resample$RMSE, digits=3))
  t1 <- paste("Summary resample$RMSE", " ", paste(t1, collapse="\n"), sep = "\n")
  t1 <- text_grob(t1, size = 10)
  
  t2 <- capture.output(postResample(pred = predicciones, obs = dsTrain.CV$SalePrice))
  t2 <- paste("Error de test", " ", paste(t2, collapse="\n"), sep = "\n")
  t2 <- text_grob(t2, size = 10)
  
  t3 <- capture.output(modelo$finalModel)
  t3 <- text_grob(paste(t3, collapse="\n"), size = 9)
  
  grid.arrange(t3, top="Modelo final")
  grid.arrange(p1, p2, t1, t2, nrow = 2, top="RMSE obtenido en la validación")
  
  if (estudioParam){
    grid.arrange(p3, nrow = 1, top="Evolución del RMSE del modelo en función de hiperparámetros")
  }
  
}

```

## Separamos los datos 

Optenemos 4 dataset

dsTrain - Que a su vez se divide en
  dsTrain.training
  dsTrain.CV 
  
dsTest

```{r}

dsTrain <- dsDataAllVarSel %>%
  filter(indTrain == 1) %>%
  select(SalePrice, everything()) %>%
  select(-c(Id,indTrain))

dim(dsTrain)

set.seed(123)
iTrain  <- createDataPartition(y=dsTrain$SalePrice, p=0.7, list=F)

dsTrain.training <- dsTrain[iTrain, ]
dsTrain.CV       <- dsTrain[-iTrain, ]

dsTest <- dsDataAllVarSel %>%
  filter(indTrain == 0) %>%
  select(SalePrice, everything()) 

```

## Definimos entrenamiento

En esta sección se entrenarán distintos modelos para evaluar cual puede ser el mejor.

Sobre cada modelo se realizará: 

* Entrenamiento
* Ajuste de hiperparámetros
* Evaluación mediante validación cruzada 

```{r}
particiones  <- 5
repeticiones <- 5

# Entrenamiento con conjunto de hiperparametros
fitControl <- trainControl(method = "repeatedcv", 
                              number = particiones,
                              repeats = repeticiones, 
                              returnResamp = "final", 
                              verboseIter = FALSE,
                              allowParallel = TRUE)
```

## Modelos

He seleccionado los 4 modelos que mejor resultado han dado en el TFM.

### Support Vector Machines with Radial Basis Function Kernel

Aunque Las máquinas de vectores soporte fueron pensadas para resolver problemas de clasificación también pueden adaptarse para resolver problemas de regresión, estos modelos dan bastante buenos resultados cuando la variable objetivo no es separables linealmente dentro del espacio vectorial de los predictores y evitan en gran medida el problema del sobreajuste a los ejemplos de entrenamiento, por ello es una buena elección para este problema.

Las máquinas de soporte utilizan una función denominada Kernel para la búsqueda del hiperplano de separación, para ello mapean los datos en espacios de dimensiones superiores con la esperanza de que en este espacio de dimensiones superiores los datos puedan separarse más fácilmente o estar mejor estructurados. 

Radial Basis permite seleccionar círculos (o hiperesferas)

```{r}

hiperparametros <- expand.grid(sigma = c(0.0005, 0.001, 0.005)
                               ,C = c(1 , 20, 50, 100, 150, 200))

t <- proc.time() # Inicia el cronómetro
modelo_svmRadial <- train(SalePrice ~ .
                          , data = dsTrain.training
                          , method = "svmRadial"
                          , tuneGrid = hiperparametros
                          , metric = "RMSE"
                          , trControl = fitControl)
proc.time()-t    # Detiene el cronómetro

modelo_svmRadial

# Presento estudio 
fnEstudioModelo(modelo_svmRadial)

```

## Elasticnet

Es una combinación de LASSO y Ridge regression, donde  predictores altamente correlacionados presentan coeficientes estimados similares. 

```{r}

hiperparametros <- expand.grid(alpha=seq(0,1,by=.5),lambda=seq(0,0.2,by=.1))

t <- proc.time() # Inicia el cronómetro
modelo_glmnet <- train(SalePrice ~ .
                          , data = dsTrain.training
                          , method = "glmnet"
                          , tuneGrid = hiperparametros
                          , metric = "RMSE"
                          , trControl = fitControl)
proc.time()-t    # Detiene el cronómetro

modelo_glmnet

# Presento estudio 
fnEstudioModelo(modelo_glmnet)

```

## LASSO

0perador de mínima contracción y selección absoluta. (least absolute shrinkage and selection operator) se utiliza para modelos de sistemas no lineales. 

Realiza selección de variables y regularización para mejorar la exactitud e interpretabilidad del modelo. Establece algunos coeficientes a cero lo que permite eliminar variables. 


```{r}

hiperparametros <- expand.grid(fraction=c(1,0.1,0.01,0.001))

t <- proc.time() # Inicia el cronómetro
modelo_lasso <- train(SalePrice ~ .
                          , data = dsTrain.training
                          , method = "lasso"
                          , tuneGrid = hiperparametros
                          #, tuneLength = 10
                          , metric = "RMSE"
                          , trControl = fitControl)
proc.time()-t    # Detiene el cronómetro

modelo_lasso

# Presento estudio 
fnEstudioModelo(modelo_lasso, estudioParam = FALSE)

```

### Generalized Linear Model

Es una generalización flexible de la regresión lineal, permite que el modelo lineal se relacione con la variable de respuesta a través de una función de enlace. Este modelo parece más apto para nuestro problema ya que permite que la variable respuesta tenga una distribución arbitraria, nuestra variable es solo positiva y varia gran escala, es una distribución sesgada.

```{r}

hiperparametros <- data.frame(parameter = "none")

t <- proc.time() # Inicia el cronómetro
modelo_glm <- train(SalePrice ~ .
                          , data = dsTrain.training
                          , method = "glm"
                          , tuneGrid = hiperparametros
                          , metric = "RMSE"
                          , trControl = fitControl)
proc.time()-t    # Detiene el cronómetro

modelo_glm

# Presento estudio 
fnEstudioModelo(modelo_glm, estudioParam = FALSE)

```

## Comparación de modelos

En este punto trataremos de identificar cual de los modelos es mejor para ello tendremos en cuenta las metricas de validación calculadas en el entrenamiento y el error de test.

Utilizare la función resamples() para extraer las metricas de los modelos entrenados.

```{r}
modelos <- list(
  SVMR = modelo_svmRadial
  ,GLMNET = modelo_glmnet
  ,GLM = modelo_glm
  ,LASSO = modelo_lasso
)

resultados_resamples <- resamples(modelos)

# Separamos el nombre del modelo y las métricas en columnas distintas.
metricas_resamples <- resultados_resamples$values %>%
                         gather(key = "modelo", value = "valor", -Resample) %>%
                         separate(col = "modelo", into = c("modelo", "metrica"),
                                  sep = "~", remove = TRUE)

# Se obtienen las medias por modelo
metricas_resamples %>% 
  group_by(modelo, metrica) %>% 
  summarise(media = mean(valor)) %>%
  spread(key = metrica, value = media) %>%
  arrange(RMSE)

predicciones <- extractPrediction(
                  models = modelos,
                  testX = dsTrain.CV[, -1],
                  testY = dsTrain.CV$SalePrice
                  )

metricas_tipo <- predicciones %>%
                         group_by(object, dataType) %>%
                         summarise(RMSE = RMSE(pred, obs))

metricas <- metricas_tipo %>%
  spread(key = dataType, RMSE) %>%
  arrange(Test)

metricas

```




                

